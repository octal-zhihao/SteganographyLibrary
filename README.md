# StegoBench
ç”Ÿæˆå¼æ–‡æœ¬éšå†™åŸºå‡†ç®—æ³•åº“

---

## ğŸ§± ç›®å½•ç»“æ„ï¼šStegoBenchï¼ˆå¤šæ¨¡å‹ + å¤šç®—æ³•æ”¯æŒï¼‰

```
StegoBench/
â”œâ”€â”€ stego_algorithms/                     # å„ç§éšå†™æ–¹æ³•æ¨¡å—
â”‚   â””â”€â”€ bins_lstm/
â”‚       â”œâ”€â”€ stego_engine.py              # åµŒå…¥/è§£ç é€»è¾‘
â”‚       â”œâ”€â”€ vocab_bins.py                # åˆ† bin å·¥å…·
â”œâ”€â”€ language_models/                     # æ¨¡å‹é€‚é…å±‚ï¼ˆåŸºäº ModelScopeï¼‰
â”‚   â”œâ”€â”€ base.py                          # BaseLanguageModel æŠ½è±¡ç±»
â”‚   â”œâ”€â”€ gpt2_wrapper.py                  # GPT2 å°è£…ï¼ˆModelScopeï¼‰
â”‚   â”œâ”€â”€ qwen_wrapper.py                  # Qwen å°è£…ï¼ˆæ”¯æŒ AutoTokenizerï¼‰
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ bit_utils.py                     # å­—ç¬¦ä¸²/æ¯”ç‰¹è½¬æ¢
â”‚   â””â”€â”€ registry.py                      # æ¨¡å‹æ³¨å†Œå™¨
â”œâ”€â”€ config/
â”‚   â””â”€â”€ model_config.yaml                # é…ç½®æ–‡ä»¶ï¼ˆè·¯å¾„/æ¨¡å‹åï¼‰
â”œâ”€â”€ main.py                              # ä¸»ç¨‹åºå…¥å£
â””â”€â”€ test_cases/
    â””â”€â”€ test_bins_lstm.py               # ç¤ºä¾‹æµ‹è¯•è„šæœ¬
```

---

## ğŸ§  language_models/base.py

```python
# language_models/base.py
import torch
from abc import ABC, abstractmethod

class BaseLanguageModel(ABC):
    @abstractmethod
    def encode(self, text: str) -> list:
        pass

    @abstractmethod
    def decode(self, token_ids: list) -> str:
        pass

    @abstractmethod
    def predict_logits(self, input_ids: torch.Tensor) -> torch.Tensor:
        """è¿”å›æœ€åä¸€ä¸ª token çš„ logits"""
        pass

    @abstractmethod
    def get_vocab_size(self) -> int:
        pass
```

---

## ğŸ§  language_models/gpt2_wrapper.pyï¼ˆModelScope GPT2ï¼‰

```python
# language_models/gpt2_wrapper.py
import torch
import torch.nn as nn
from modelscope import GPT2Tokenizer, GPT2Model
from language_models.base import BaseLanguageModel

class GPT2Wrapper(BaseLanguageModel):
    def __init__(self, model_path='openai-community/gpt2'):
        self.tokenizer = GPT2Tokenizer.from_pretrained(model_path)
        self.model = GPT2Model.from_pretrained(model_path)
        self.proj = nn.Linear(self.model.config.hidden_size, self.model.config.vocab_size, bias=False)
        self.model.eval()
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.model.to(self.device)
        self.proj.to(self.device)

    def encode(self, text):
        return self.tokenizer(text)["input_ids"]

    def decode(self, token_ids):
        return self.tokenizer.decode(token_ids)

    def predict_logits(self, input_ids: torch.Tensor):
        with torch.no_grad():
            output = self.model(input_ids.to(self.device))
            hidden = output.last_hidden_state[:, -1]
            logits = self.proj(hidden).squeeze(0)
        return logits

    def get_vocab_size(self):
        return self.model.config.vocab_size
```

---

## ğŸ§  utils/bit_utils.py

```python
def str_to_bits(s):
    return ''.join(f'{ord(c):08b}' for c in s)

def bits_to_str(bits):
    chars = [chr(int(bits[i:i+8], 2)) for i in range(0, len(bits), 8)]
    return ''.join(chars)
```

---

## ğŸ§  utils/registry.pyï¼ˆæ¨¡å‹å·¥å‚ï¼‰

```python
# utils/registry.py
from language_models.gpt2_wrapper import GPT2Wrapper
from language_models.qwen_wrapper import QwenWrapper

MODEL_REGISTRY = {
    'gpt2': GPT2Wrapper,
    'qwen': QwenWrapper,
}

def get_model(model_name):
    return MODEL_REGISTRY[model_name]()
```

---

## ğŸ§  stego_algorithms/bins_lstm/stego_engine.pyï¼ˆç®€åŒ–æ¥å£ï¼‰

```python
import torch
import random

def embed_bits(lm, tokenizer, bins, bit_string, max_len=32, temperature=1.0, top_k=10):
    tokens = []
    input_ids = torch.tensor([lm.encode(" ")], dtype=torch.long).to(lm.device)

    for i in range(0, len(bit_string), 2):
        bit_block = bit_string[i:i+2]
        bin_tokens = bins[bit_block]

        logits = lm.predict_logits(input_ids) / temperature
        probs = torch.softmax(logits, dim=-1)

        filtered = [(i, probs[i].item()) for i in bin_tokens if i < probs.size(0)]
        filtered.sort(key=lambda x: x[1], reverse=True)
        filtered = filtered[:top_k]
        ids, values = zip(*filtered)
        dist = torch.distributions.Categorical(probs=torch.tensor(values))
        next_token = ids[dist.sample().item()]

        tokens.append(next_token)
        input_ids = torch.cat([input_ids, torch.tensor([[next_token]]).to(lm.device)], dim=1)
        if len(tokens) >= max_len:
            break

    return tokenizer.decode(tokens)

def decode_bits(text, bins, tokenizer):
    ids = tokenizer(text)["input_ids"]
    inverse_map = {tok_id: bits for bits, tok_set in bins.items() for tok_id in tok_set}
    decoded = [inverse_map[i] for i in ids if i in inverse_map]
    return ''.join(decoded)
```

---

## ğŸ§ª main.py ç¤ºä¾‹

```python
# main.py
import argparse
from utils.registry import get_model
from stego_algorithms.bins_lstm.vocab_bins import build_bins
from stego_algorithms.bins_lstm.stego_engine import embed_bits, decode_bits
from utils.bit_utils import str_to_bits, bits_to_str

def main(args):
    model = get_model(args.model)
    vocab_ids = list(range(model.get_vocab_size()))
    bins = build_bins(vocab_ids, num_bins=4)

    bit_string = str_to_bits(args.text)
    stego = embed_bits(model, model.tokenizer, bins, bit_string)
    print(f"[Stego Text]: {stego}")

    decoded_bits = decode_bits(stego, bins, model.tokenizer)
    print(f"[Recovered]: {bits_to_str(decoded_bits[:len(bit_string)])}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--model', type=str, default='gpt2', help='gpt2 / qwen / chatglm')
    parser.add_argument('--text', type=str, required=True)
    args = parser.parse_args()
    main(args)
```

---

## âœ… è¿è¡Œç¤ºä¾‹

```bash
# åˆ‡æ¢ç›®å½•åˆ°é¡¹ç›®æ ¹ç›®å½•
cd StegoBench

# åµŒå…¥ hello ç”¨ gpt2
python main.py --model gpt2 --text hello
```

---

## âœ… ä¸‹ä¸€æ­¥å¯é€‰æ‰©å±•

| åŠŸèƒ½ | è¯´æ˜ |
|------|------|
| todo åŠ å…¥ qwen_wrapper.py | æ”¯æŒ qwen/Qwen-7B-Chatï¼ˆé€šè¿‡ `AutoModelForCausalLM`ï¼‰ |
| todo æ”¯æŒå¤šä¸ªç®—æ³• | `--algo bins_lstm` å‚æ•°åˆ‡æ¢ä¸åŒç®—æ³• |
| todo æ”¯æŒå¤šè¯„æµ‹æŒ‡æ ‡ | BLEUã€å›°æƒ‘åº¦ã€GPTè¯„åˆ†ã€å¯è§£æ€§ç­‰ |

---